{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dCpvgG0vwXAZ"},"source":["#Sentiment Analysis with BERT\n","\n"]},{"cell_type":"code","metadata":{"id":"hhbGEfwgdEtw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606384523658,"user_tz":-480,"elapsed":31308,"user":{"displayName":"Evanna Lynch","photoUrl":"","userId":"05073261002217090301"}},"outputId":"b9c35968-ac4a-4ce6-d38a-6c1297ed351c"},"source":["!pip install bert-tensorflow==1.0.1\n","%tensorflow_version 1.x\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","import bert\n","from bert import run_classifier\n","from google.colab import drive\n","drive.mount('/content/drive')\n","OUTPUT_DIR = '/content/drive/My Drive/6000/fine-tuning'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow==1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.1\n","TensorFlow 1.x selected.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fom_ff20gyy6"},"source":["def load_data(input_path):\n","  df = pd.read_csv(input_path)\n","  df['emotion'] = df['emotion'].astype('int')\n","  df['text'] = df['text'].astype('str')\n","  return df\n","\n","train = load_data('/content/drive/My Drive/6000/train.csv')\n","test = load_data('/content/drive/My Drive/6000/test.csv')\n","\n","for i in range(len(train)):\n","  if train.loc[i,'emotion']==1:\n","    train.loc[i,'emotion']=0\n","  if train.loc[i,'emotion']==2:\n","    train.loc[i,'emotion']=1\n","  if train.loc[i,'emotion']==3:\n","    train.loc[i,'emotion']=2\n","  if train.loc[i,'emotion']==4:\n","    train.loc[i,'emotion']=2\n","\n","for i in range(len(test)):\n","  if test.loc[i,'emotion']==1:\n","    test.loc[i,'emotion']=0\n","  if test.loc[i,'emotion']==2:\n","    test.loc[i,'emotion']=1\n","  if test.loc[i,'emotion']==3:\n","    test.loc[i,'emotion']=2\n","  if test.loc[i,'emotion']==4:\n","    test.loc[i,'emotion']=2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3hvY-DSHaba"},"source":["DATA_COLUMN = 'text'\n","LABEL_COLUMN = 'emotion'\n","label_list = [0,1,2]\n","\n","# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n","test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhJSe0QHNG7U"},"source":["# This is a path to a chinese version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()\n","\n","# Convert our train and test features to InputFeatures that BERT understands.\n","MAX_SEQ_LENGTH = 128\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6o2a5ZIvRcJq"},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n","  \"\"\"Creates a classification model.\"\"\"\n","\n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.5)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnH-AnOQ9KKW"},"source":["# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        return {\n","            \"eval_accuracy\": accuracy\n","        }\n","        \n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjwJ4bTeWXD8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606384593284,"user_tz":-480,"elapsed":100869,"user":{"displayName":"Evanna Lynch","photoUrl":"","userId":"05073261002217090301"}},"outputId":"bd8a68eb-fb63-4a51-b9cc-d3e8ddd981f5"},"source":["# Compute train and warmup steps from batch size\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 1000\n","SAVE_SUMMARY_STEPS = 200\n","\n","# Compute # train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","print(num_train_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oEJldMr3WYZa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606384593286,"user_tz":-480,"elapsed":100853,"user":{"displayName":"Evanna Lynch","photoUrl":"","userId":"05073261002217090301"}},"outputId":"d036b2c3-c6ff-475b-99be-bfc526dd3a2c"},"source":["# Specify outpit directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n","\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})\n","\n","# Create an input function for training. drop_remainder = True for using TPUs.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/6000/fine-tuning', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f75d71c1c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/6000/fine-tuning', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f75d71c1c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"t6Nukby2EB6-"},"source":["Beginning Training"]},{"cell_type":"code","metadata":{"id":"nucD4gluYJmK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606384595163,"user_tz":-480,"elapsed":102715,"user":{"displayName":"Evanna Lynch","photoUrl":"","userId":"05073261002217090301"}},"outputId":"625df476-0565-45bb-db07-1f15dcd953cb"},"source":["print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","INFO:tensorflow:Skipping training since max_steps has already saved.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Skipping training since max_steps has already saved.\n"],"name":"stderr"},{"output_type":"stream","text":["Training took time  0:00:01.578128\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gOC2wvBldCl8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606384653489,"user_tz":-480,"elapsed":161029,"user":{"displayName":"Evanna Lynch","photoUrl":"","userId":"05073261002217090301"}},"outputId":"2d1ca1a6-b038-4f65-8785-5cf127f743fe"},"source":["test_input_fn = run_classifier.input_fn_builder(\n","    features=test_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)\n","\n","estimator.evaluate(input_fn=test_input_fn, steps=None)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-5-9ad33005a732>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-5-9ad33005a732>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-11-26T09:56:50Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-11-26T09:56:50Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/drive/My Drive/6000/fine-tuning/model.ckpt-3857\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/drive/My Drive/6000/fine-tuning/model.ckpt-3857\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-11-26-09:57:30\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-11-26-09:57:30\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 3857: eval_accuracy = 0.91943127, global_step = 3857, loss = 0.32294774\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 3857: eval_accuracy = 0.91943127, global_step = 3857, loss = 0.32294774\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3857: /content/drive/My Drive/6000/fine-tuning/model.ckpt-3857\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3857: /content/drive/My Drive/6000/fine-tuning/model.ckpt-3857\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'eval_accuracy': 0.91943127, 'global_step': 3857, 'loss': 0.32294774}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"uswsaJppMK0B"},"source":[""],"execution_count":null,"outputs":[]}]}